package raft

import (
	"container/list"
	"fmt"
	"sync/atomic"
	"time"
)

// runLeader åœ¨è¿™é‡Œè®¾ç½®è®©leaderè¿è¡ŒFSMï¼Œå¹¶å°†å…¶æ”¾å…¥leaderLoop
func (r *Raft) runLeader() {
	r.logger.Info("è¿›å…¥ leader state", "leader", r)

	// é€šçŸ¥æ‰€æœ‰äººï¼Œåªæ˜¯å°†true æ”¾å…¥äº†leaderCh
	overrideNotifyBool(r.leaderCh, true)

	// å­˜å‚¨é€šçŸ¥é€šé“ã€‚å®ƒæ˜¯ä¸å¯é‡è½½çš„ï¼Œæ‰€ä»¥åœ¨ä¸‹é¢çš„deferè¿è¡Œä¹‹å‰ä¸åº”è¯¥æ”¹å˜ï¼Œä½†è¿™å¯ä»¥ç¡®ä¿æˆ‘ä»¬åœ¨è·å¾—å’Œå¤±å»é¢†å¯¼æƒçš„æƒ…å†µä¸‹æ€»æ˜¯é€šçŸ¥åŒä¸€ä¸ªchanã€‚
	notify := r.config().NotifyCh // nil å› ä¸ºæ²¡æœ‰èµ‹å€¼çš„åœ°æ–¹

	// å¦‚æœç»™å®šçš„è¯ï¼Œæ¨é€åˆ°é€šçŸ¥é€šé“
	if notify != nil {
		select {
		case notify <- true:
		case <-r.shutdownCh:
		}
	}

	// è®¾ç½®é¢†å¯¼çŠ¶æ€ã€‚è¿™åº”è¯¥åªåœ¨leaderLoopä¸­è¢«è®¿é—®ã€‚
	r.setupLeaderState()

	// è¿è¡Œä¸€ä¸ªåå°go-routineæ¥æ’æ”¾æ—¥å¿—å¹´é¾„çš„æŒ‡æ ‡
	stopCh := make(chan struct{})

	// todo é™çº§æ—¶çš„æ¸…ç†çŠ¶æ€
	defer func() {
		close(stopCh)

		// ç”±äºæˆ‘ä»¬ä¹‹å‰æ˜¯é¢†å¯¼ï¼Œæ‰€ä»¥å½“æˆ‘ä»¬ä¸æ˜¯æ—¶ï¼Œæˆ‘ä»¬ä¼šæ›´æ–°æˆ‘ä»¬çš„æœ€åè”ç³»æ—¶é—´ï¼Œ
		// è¿™æ ·æˆ‘ä»¬å°±ä¸ä¼šæŠ¥å‘Šæˆ‘ä»¬æ˜¯é¢†å¯¼ä¹‹å‰çš„æœ€åè”ç³»æ—¶é—´äº†ã€‚å¦åˆ™ï¼Œå¯¹å®¢æˆ·æ¥è¯´ï¼Œæˆ‘ä»¬çš„æ•°æ®ä¼šæ˜¾å¾—éå¸¸é™ˆæ—§ã€‚
		r.setLastContact()

		// åœæ­¢å¤åˆ¶
		for _, p := range r.leaderState.replState {
			close(p.stopCh)
		}

		// å“åº”æ‰€æœ‰é£è¡Œè¡ŒåŠ¨
		for e := r.leaderState.inflight.Front(); e != nil; e = e.Next() {
			e.Value.(*logFuture).respond(ErrLeadershipLost)
		}

		// Respond to any pending verify requests
		for future := range r.leaderState.notify {
			future.respond(ErrLeadershipLost)
		}

		// Clear all the state
		r.leaderState.commitCh = nil
		r.leaderState.commitment = nil
		r.leaderState.inflight = nil
		r.leaderState.replState = nil
		r.leaderState.notify = nil
		r.leaderState.stepDown = nil

		// If we are stepping down for some reason, no known leader.
		// We may have stepped down due to an RPC call, which would
		// provide the leader, so we cannot always blank this out.
		r.leaderLock.Lock()
		if r.leader == r.localAddr {
			r.leader = ""
		}
		r.leaderLock.Unlock()

		// Notify that we are not the leader
		overrideNotifyBool(r.leaderCh, false)

		// Push to the notify channel if given
		if notify != nil {
			select {
			case notify <- false:
			case <-r.shutdownCh:
				// On shutdown, make a best effort but do not block
				select {
				case notify <- false:
				default:
				}
			}
		}
	}()

	// å¯¹æ¯ä¸€ä¸ªèŠ‚ç‚¹å¯åŠ¨ä¸€ä¸ªå¤åˆ¶ go routine  æ—¥å¿—å¤åˆ¶ã€å¿ƒè·³æ£€æµ‹
	r.startStopReplication()
	// å…ˆåˆ†å‘ä¸€ä¸ªæ— æ“ä½œçš„æ—¥å¿—æ¡ç›®ã€‚å³ä½¿åœ¨æ²¡æœ‰å®¢æˆ·ç«¯å‘½ä»¤çš„æƒ…å†µä¸‹ï¼Œè¿™ä¹Ÿä¼šä½¿leaderè¾¾åˆ°æœ€æ–°çš„å¯èƒ½æäº¤ç´¢å¼•ã€‚
	// è¿™ç”¨äºè¿½åŠ é…ç½®é¡¹è€Œä¸æ˜¯noopã€‚
	// ä½†æ˜¯ï¼Œè¿™å…è®¸æ—¥å¿—ä¸­æœ‰æ— æ•°ä¸ªæœªæäº¤çš„é…ç½®ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬è®¤ä¸ºåœ¨ä»»ä½•æ—¥å¿—ä¸­æœ€å¤šåªå­˜åœ¨ä¸€ä¸ªæœªæäº¤çš„é…ç½®æ¡ç›®ï¼Œå› æ­¤æˆ‘ä»¬å¿…é¡»åœ¨è¿™é‡Œè¿›è¡Œé€‚å½“çš„æ— æ“ä½œã€‚
	noop := &logFuture{
		log: Log{
			Type: LogNoop,
		},
	}
	r.dispatchLogs([]*logFuture{noop})
	r.leaderLoop()
}

// leaderLoop å®ƒåœ¨æ‰€æœ‰ä¸åŒçš„leaderè®¾ç½®å®Œæˆåè¢«è°ƒç”¨ã€‚
func (r *Raft) leaderLoop() {
	// stepDownç”¨æ¥è¿½è¸ªæ˜¯å¦æœ‰é£è¡Œæ—¥å¿—ä¼šå¯¼è‡´æˆ‘ä»¬å¤±å»é¢†å¯¼èƒ½åŠ›(ç‰¹åˆ«æ˜¯æˆ‘ä»¬è‡ªå·±çš„ä¸€ä¸ªRemovePeer)ã€‚
	// å¦‚æœæ˜¯è¿™ç§æƒ…å†µï¼Œæˆ‘ä»¬ä¸èƒ½å…è®¸ä»»ä½•æ—¥å¿—å¹¶è¡Œå¤„ç†ï¼Œå¦åˆ™æˆ‘ä»¬å°†åªåŸºäºå•ä¸ªfollower(æˆ‘ä»¬è‡ªå·±)æäº¤ï¼Œå¹¶å¤åˆ¶åˆ°ä¸€ç»„æœªå®šä¹‰çš„å¯¹ç­‰ä½“ã€‚
	stepDown := false
	// è¿™åªç”¨äºç¬¬ä¸€æ¬¡ç§Ÿçº¦æ£€æŸ¥ï¼Œæˆ‘ä»¬åœ¨ä¸‹é¢æ ¹æ®å½“å‰é…ç½®å€¼é‡æ–°åŠ è½½ç§Ÿçº¦ã€‚
	lease := time.After(r.config().LeaderLeaseTimeout)

	for r.getState() == Leader {
		select {
		case rpc := <-r.rpcCh: // over
			r.processRPC(rpc)
		case <-r.leaderState.stepDown:
			r.setState(Follower)
		case future := <-r.leadershipTransferCh: // runLeader ç›‘å¬leaderè½¬ç§»
			if r.getLeadershipTransferInProgress() {
				// å¦‚æœå·²ç»åœ¨è½¬ç§»ä¸­äº†
				r.logger.Debug(ErrLeadershipTransferInProgress.Error())
				future.respond(ErrLeadershipTransferInProgress)
				continue
			}
			r.logger.Debug("leaderå¼€å§‹è½¬ç§»åˆ°", "id", future.ID, "address", future.Address)
			// å½“ç¦»å¼€ leaderLoop,ä¸å†æ˜¯leader, éœ€è¦å…³é—­leftLeaderLoop
			leftLeaderLoop := make(chan struct{})
			defer func() { close(leftLeaderLoop) }()
			stopCh := make(chan struct{})
			doneCh := make(chan error, 1)

			// è¿™æ˜¯åœ¨é¢†å¯¼æƒè½¬ç§»å‡½æ•°ä¹‹å¤–æ•…æ„è®¾ç½®çš„ã€‚
			// å› ä¸ºTimeoutNowè°ƒç”¨æ˜¯é˜»å¡çš„ï¼Œè€Œä¸”æ²¡æœ‰åŠæ³•åœ¨å®šæ—¶å™¨è¿‡æœŸçš„æƒ…å†µä¸‹ä¸­æ­¢å®ƒã€‚
			// leadershipTransferå‡½æ•°æ˜¯ç”±stopChå’ŒdoneChæ§åˆ¶çš„ã€‚
			go func() {
				select {
				case <-time.After(r.config().ElectionTimeout):
					close(stopCh)
					err := fmt.Errorf("leadership transfer timeout")
					r.logger.Debug(err.Error())
					future.respond(err)
					<-doneCh
				case <-leftLeaderLoop:
					close(stopCh)
					err := fmt.Errorf("lost leadership during transfer (expected)")
					r.logger.Debug(err.Error())
					future.respond(nil)
					<-doneCh
				case err := <-doneCh:
					if err != nil {
						r.logger.Debug(err.Error())
					}
					future.respond(err)
				}
			}()

			// leaderState.replState is accessed here before
			// starting leadership transfer asynchronously because
			// leaderState is only supposed to be accessed in the
			// leaderloop.
			id := future.ID
			address := future.Address
			if id == nil {
				s := r.pickServer()
				if s != nil {
					id = &s.ID
					address = &s.Address
				} else {
					doneCh <- fmt.Errorf("cannot find peer")
					continue
				}
			}
			state, ok := r.leaderState.replState[*id]
			if !ok {
				doneCh <- fmt.Errorf("cannot find replication state for %v", id)
				continue
			}

			go r.leadershipTransfer(*id, *address, state, stopCh, doneCh)
		case <-r.leaderState.commitCh:
			// Process the newly committed entries
			oldCommitIndex := r.getCommitIndex()
			commitIndex := r.leaderState.commitment.getCommitIndex()
			r.setCommitIndex(commitIndex)

			// New configration has been committed, set it as the committed
			// value.
			if r.configurations.latestIndex > oldCommitIndex &&
				r.configurations.latestIndex <= commitIndex {
				r.setCommittedConfiguration(r.configurations.latest, r.configurations.latestIndex)
				if !hasVote(r.configurations.committed, r.localID) {
					stepDown = true
				}
			}

			var groupReady []*list.Element
			var groupFutures = make(map[uint64]*logFuture)
			var lastIdxInGroup uint64

			// Pull all inflight logs that are committed off the queue.
			for e := r.leaderState.inflight.Front(); e != nil; e = e.Next() {
				commitLog := e.Value.(*logFuture)
				idx := commitLog.log.Index
				if idx > commitIndex {
					// Don't go past the committed index
					break
				}

				// Measure the commit time
				groupReady = append(groupReady, e)
				groupFutures[idx] = commitLog
				lastIdxInGroup = idx
			}

			// Process the group
			if len(groupReady) != 0 {
				r.processLogs(lastIdxInGroup, groupFutures)

				for _, e := range groupReady {
					r.leaderState.inflight.Remove(e)
				}
			}

			if stepDown {
				if r.config().ShutdownOnRemove {
					r.logger.Info("removed ourself, shutting down")
					r.Shutdown()
				} else {
					r.logger.Info("removed ourself, transitioning to follower")
					r.setState(Follower)
				}
			}
		case v := <-r.verifyCh:
			if v.quorumSize == 0 {
				// åˆšå‘é€ï¼Œå¼€å§‹æ ¸æŸ¥
				r.verifyLeader(v)

			} else if v.votes < v.quorumSize {
				// ææ—©å›æ¥ï¼Œæ„å‘³ç€å¿…é¡»æœ‰ä¸€ä¸ªæ–°çš„é¢†è¢–
				r.logger.Warn("new leader elected, stepping down")
				r.setState(Follower)
				delete(r.leaderState.notify, v)
				for _, repl := range r.leaderState.replState {
					repl.cleanNotify(v)
				}
				v.respond(ErrNotLeader)

			} else {
				// Quorum of members agree, we are still leader
				delete(r.leaderState.notify, v)
				for _, repl := range r.leaderState.replState {
					repl.cleanNotify(v)
				}
				v.respond(nil)
			}
		case future := <-r.userRestoreCh:
			if r.getLeadershipTransferInProgress() {
				r.logger.Debug(ErrLeadershipTransferInProgress.Error())
				future.respond(ErrLeadershipTransferInProgress)
				continue
			}
			err := r.restoreUserSnapshot(future.meta, future.reader)
			future.respond(err)
		case future := <-r.configurationsCh:
			if r.getLeadershipTransferInProgress() {
				r.logger.Debug(ErrLeadershipTransferInProgress.Error())
				future.respond(ErrLeadershipTransferInProgress)
				continue
			}
			future.configurations = r.configurations.Clone()
			future.respond(nil)
		case future := <-r.configurationChangeChIfStable():
			if r.getLeadershipTransferInProgress() {
				r.logger.Debug(ErrLeadershipTransferInProgress.Error())
				future.respond(ErrLeadershipTransferInProgress)
				continue
			}
			r.appendConfigurationEntry(future)
		case b := <-r.bootstrapCh: // over ğŸˆ²
			b.respond(ErrCantBootstrap)
		case newLog := <-r.applyCh: // over
			if r.getLeadershipTransferInProgress() { // åˆ¤æ–­æ˜¯ä¸æ˜¯åœ¨è½¬ç§»leader
				r.logger.Debug(ErrLeadershipTransferInProgress.Error())
				newLog.respond(ErrLeadershipTransferInProgress)
				continue
			}
			// é›†ä½“æäº¤ï¼Œæ”¶é›†æ‰€æœ‰å‡†å¤‡å¥½çš„æäº¤
			ready := []*logFuture{newLog}
		GroupCommitLoop:
			for i := 0; i < r.config().MaxAppendEntries; i++ {
				select {
				case newLog := <-r.applyCh:
					ready = append(ready, newLog)
				default:
					break GroupCommitLoop
				}
			}

			// å‘é€æ—¥å¿—
			if stepDown {
				// æˆ‘ä»¬æ­£åœ¨å¸ä»»é¢†å¯¼èŒåŠ¡ï¼Œä¸è¦å¤„ç†ä»»ä½•æ–°çš„æ•°æ®ã€‚
				for i := range ready {
					ready[i].respond(ErrNotLeader)
				}
			} else {
				r.dispatchLogs(ready)
			}
		case <-lease: // over

			// çœ‹çœ‹æˆ‘ä»¬æ˜¯å¦è¶…è¿‡äº†ç§Ÿçº¦ï¼Œå¯èƒ½ä¼šè¾èŒ
			// è°ƒæ•´ä¸‹ä¸€æ¬¡æ£€æŸ¥å„èŠ‚ç‚¹é€šä¿¡èŠ‚ç‚¹çš„æ—¶é—´
			maxDiff := r.checkLeaderLease()

			// ä¸‹æ¬¡æ£€æŸ¥çš„é—´éš”åº”è¯¥è°ƒæ•´ä¸ºæˆ‘ä»¬è”ç³»çš„æœ€åä¸€ä¸ªèŠ‚ç‚¹ï¼Œè€Œä¸æ˜¯è´Ÿæ•°
			checkInterval := r.config().LeaderLeaseTimeout - maxDiff
			if checkInterval < minCheckInterval {
				checkInterval = minCheckInterval
			}
			lease = time.After(checkInterval)
		case <-r.shutdownCh:
			return
		}
	}
}

// verifyLeader
func (r *Raft) verifyLeader(v *verifyFuture) {
	// ç°ä»»é¢†å¯¼äººæ€»æ˜¯ä¸ºè‡ªå·±æŠ•ç¥¨
	v.votes = 1

	// è®¾ç½®è·èƒœéœ€è¦çš„ç¥¨æ•°
	v.quorumSize = r.quorumSize()
	if v.quorumSize == 1 {
		v.respond(nil)
		return
	}

	// è¿½è¸ªè¯·æ±‚
	v.notifyCh = r.verifyCh
	r.leaderState.notify[v] = struct{}{}

	// ç«‹å³å¼•å‘å¿ƒè·³
	for _, repl := range r.leaderState.replState {
		repl.notifyLock.Lock()
		repl.notify[v] = struct{}{}
		repl.notifyLock.Unlock()
		asyncNotifyCh(repl.notifyCh)
	}
}

func (r *Raft) leadershipTransfer(id ServerID, address ServerAddress, repl *followerReplication, stopCh chan struct{}, doneCh chan error) {

	// ç¡®ä¿æˆ‘ä»¬æ²¡æœ‰è¢«é˜»æ­¢
	select {
	case <-stopCh:
		doneCh <- nil
		return
	default:
	}

	// Step 1: set this field which stops this leader from responding to any client requests.
	r.setLeadershipTransferInProgress(true)
	defer func() { r.setLeadershipTransferInProgress(false) }()

	for atomic.LoadUint64(&repl.nextIndex) <= r.getLastIndex() {
		err := &deferError{}
		err.init()
		repl.triggerDeferErrorCh <- err
		select {
		case err := <-err.errCh:
			if err != nil {
				doneCh <- err
				return
			}
		case <-stopCh:
			doneCh <- nil
			return
		}
	}

	// Step ?: the thesis describes in chap 6.4.1: Using clocks to reduce
	// messaging for read-only queries. If this is implemented, the lease
	// has to be reset as well, in case leadership is transferred. This
	// implementation also has a lease, but it serves another purpose and
	// doesn't need to be reset. The lease mechanism in our raft lib, is
	// setup in a similar way to the one in the thesis, but in practice
	// it's a timer that just tells the leader how often to check
	// heartbeats are still coming in.

	// Step 3: send TimeoutNow message to target server.
	err := r.trans.TimeoutNow(id, address, &TimeoutNowRequest{RPCHeader: r.getRPCHeader()}, &TimeoutNowResponse{})
	if err != nil {
		err = fmt.Errorf("failed to make TimeoutNow RPC to %v: %v", id, err)
	}
	doneCh <- err
}

func (r *Raft) setupLeaderState() {
	r.leaderState.commitCh = make(chan struct{}, 1)
	r.leaderState.commitment = newCommitment(r.leaderState.commitCh,
		r.configurations.latest,
		r.getLastIndex()+1, // è¿™ä¸ªä»»æœŸå†…ï¼Œæœ€æ—©æäº¤çš„index
	)
	r.leaderState.inflight = list.New()
	r.leaderState.replState = make(map[ServerID]*followerReplication)
	r.leaderState.notify = make(map[*verifyFuture]struct{})
	r.leaderState.stepDown = make(chan struct{}, 1)
}

// ------------------------------------ over ------------------------------------

// setLeader æ˜¯ç”¨æ¥ä¿®æ”¹é›†ç¾¤çš„å½“å‰é¢†å¯¼è€…çš„
func (r *Raft) setLeader(leader ServerAddress) {
	r.leaderLock.Lock()
	r.leader = leader
	r.leaderLock.Unlock()
}

// initiateLeadershipTransfer  åˆå§‹åŒ–leaderè½¬ç§»åˆ° id çš„äº‹ä»¶ï¼Œç­‰å¾…æœªæ¥è¿”å›ç»“æœ
func (r *Raft) initiateLeadershipTransfer(id *ServerID, address *ServerAddress) LeadershipTransferFuture {
	future := &leadershipTransferFuture{ID: id, Address: address}
	future.init()

	if id != nil && *id == r.localID {
		err := fmt.Errorf("ä¸èƒ½æŠŠleaderè½¬ç§»åˆ°è‡ªå·±èº«ä¸Š")
		r.logger.Info(err.Error())
		future.respond(err)
		return future
	}

	select {
	case r.leadershipTransferCh <- future:
		return future
	case <-r.shutdownCh:
		return errorFuture{ErrRaftShutdown}
	default:
		return errorFuture{ErrEnqueueTimeout}
	}
}

// OK
func (r *Raft) setLeadershipTransferInProgress(v bool) {
	if v {
		atomic.StoreInt32(&r.leaderState.leadershipTransferInProgress, 1)
	} else {
		atomic.StoreInt32(&r.leaderState.leadershipTransferInProgress, 0)
	}
}

// OK
func (r *Raft) getLeadershipTransferInProgress() bool {
	v := atomic.LoadInt32(&r.leaderState.leadershipTransferInProgress)
	return v == 1
}

// checkLeaderLease æ£€æŸ¥æ˜¯å¦ä»ä¸å¤§å¤šæ•°é€šä¿¡åœ¨è§„å®šæ—¶é—´å†…;è¿”å›æ²¡æœ‰é€šä¿¡çš„æœ€é•¿æ—¶é—´ã€‚
func (r *Raft) checkLeaderLease() time.Duration {
	// è·Ÿè¸ªå¯ä»¥é€šä¿¡çš„èŠ‚ç‚¹ï¼ŒåŒ…æ‹¬è‡ªå·±
	contacted := 0

	// å­˜å‚¨è¿™ä¸ªæ£€æŸ¥è°ƒç”¨çš„ç§Ÿçº¦è¶…æ—¶ï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦åœ¨å¾ªç¯ä¸­å¼•ç”¨å®ƒï¼Œå¦‚æœå®ƒå˜æˆå¯æ›´æ”¹çš„ï¼Œå¹¶åœ¨ä¸‹é¢çš„å¾ªç¯ä¹‹é—´æ›´æ”¹ï¼Œå°†ä¼šä»¤äººå›°æƒ‘ã€‚
	leaseTimeout := r.config().LeaderLeaseTimeout // 500ms

	var maxDiff time.Duration // é€šä¿¡é—´éš”æœ€å¤§çš„æ—¶é—´
	now := time.Now()
	for _, server := range r.configurations.latest.Servers {
		if server.Suffrage == Voter {
			if server.ID == r.localID {
				contacted++
				continue
			}
			f := r.leaderState.replState[server.ID]
			diff := now.Sub(f.LastContact())
			if diff <= leaseTimeout {
				contacted++
				if diff > maxDiff {
					maxDiff = diff
				}
			} else {
				r.logger.Warn("failed to contact", "server-id", server.ID, "time", diff)
			}
		}
	}

	quorum := r.quorumSize()
	if contacted < quorum {
		r.logger.Warn("æ— æ³•ä¸å¤§å¤šæ•°èŠ‚ç‚¹é€šä¿¡ï¼Œè®¾ç½®ä¸ºFollower")
		r.setState(Follower)
	}
	return maxDiff
}
